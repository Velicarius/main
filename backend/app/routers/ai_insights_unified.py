"""
Unified AI Insights API —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ Cursor Prompt
–†–µ–∞–ª–∏–∑—É–µ—Ç –∫–æ–Ω—Ç—Ä–∞–∫—Ç —Å —è–≤–Ω—ã–º–∏ —Ä–µ–∂–∏–º–∞–º–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é
"""

import time
import logging
from typing import Dict, Any, Optional, Tuple
from uuid import UUID
from fastapi import APIRouter, Depends, HTTPException, Query, Header, status, Response
from fastapi.responses import JSONResponse
from sqlalchemy.orm import Session
from pydantic import BaseModel, Field, ConfigDict
from datetime import datetime

from app.database import get_db
from app.services.unified_cache_service import (
    UnifiedCacheService, 
    CacheMode, 
    CacheState, 
    CacheMetadata,
    UnifiedCacheConfig
)

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/ai/insights", tags=["ai-insights-unified"])

# === Pydantic –º–æ–¥–µ–ª–∏ ===

class UnifiedInsightsRequest(BaseModel):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è unified insights"""
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞
    horizon_months: int = Field(default=6, ge=1, le=24, description="–ì–æ—Ä–∏–∑–æ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤ –º–µ—Å—è—Ü–∞—Ö")
    risk_profile: str = Field(default="Balanced", description="–ü—Ä–æ—Ñ–∏–ª—å —Ä–∏—Å–∫–∞")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    model: str = Field(default="llama3.1:8b", description="–ú–æ–¥–µ–ª—å LLM")
    temperature: float = Field(default=0.2, ge=0.0, le=2.0, description="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏")
    top_p: float = Field(default=1.0, ge=0.0, le=1.0, description="Top-p –ø–∞—Ä–∞–º–µ—Ç—Ä")
    max_tokens: int = Field(default=400, ge=50, le=2000, description="–ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤")
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    locale: str = Field(default="en", description="–Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞")
    include_signals: bool = Field(default=True, description="–í–∫–ª—é—á–∞—Ç—å —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã")


class UnifiedInsightsResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é –∫—ç—à–∞"""
    # –ü–æ–ª—è –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
    cached: bool
    cache_key: str
    model_name: str  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ —Å protected namespace
    last_updated: str  # ISO timestamp
    compute_ms: int    # server-side compute –≤—Ä–µ–º—è
    llm_ms: int = 0   # —á–∏—Å—Ç–æ–µ –≤—Ä–µ–º—è LLM –≤—ã–∑–æ–≤–∞
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç–æ–≤
    data: Dict[str, Any]
    
    model_config = ConfigDict(protected_namespaces=())


class CacheInvalidateRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—é –∫—ç—à–∞"""
    user_id: Optional[str] = None
    full_clear: bool = False


# === –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å ===

class UnifiedInsightsService:
    """–û—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å unified insights —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    
    def __init__(self):
        self.cache_service = UnifiedCacheService()
    
    async def get_insights(
        self,
        user_id: UUID,
        request: UnifiedInsightsRequest,
        cache_param: str = CacheMode.DEFAULT,
        db: Session = None,
        if_none_match: Optional[str] = None
    ) -> Tuple[Optional[Dict[str, Any]], Dict[str, str]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Å–∞–π—Ç–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ SWR (Stale-While-Revalidate)
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            request: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            cache_param: —Ä–µ–∂–∏–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è (default/bypass/refresh)
            db: —Å–µ—Å—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            if_none_match: ETag –¥–ª—è conditional requests
        
        Returns:
            (response_data, headers) - –¥–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç–∞ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
        """
        start_time = time.time()
        request_data = request.dict()
        
        logger.info(f"üîÑ Unified insights SWR request for user {user_id}, mode={cache_param}")
        
        # üéØ –ü—Ä–æ–≤–µ—Ä—è–µ–º SWR –∫—ç—à –ø–µ—Ä–≤—ã–º –¥–µ–ª–æ–º –¥–ª—è Bypass/Refresh —Ä–µ–∂–∏–º–æ–≤
        if cache_param == CacheMode.DEFAULT:
            cache_metadata, cached_data, needs_background_refresh = self.cache_service.get_insights_with_swr(
                str(user_id), request_data, if_none_match
            )
            
            # üéØ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã SWR
            
            # 304 Not Modified - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            if cached_data is None and cache_metadata:
                return None, {
                    "ETag": cache_metadata.etag,
                    "X-Cache": "HIT",
                    "X-Cache-Age": str(cache_metadata.cache_age),
                    "X-Generated-At": cache_metadata.last_updated.isoformat(),
                    "X-LLM-Model": cache_metadata.model_name,
                    "X-Features-Version": "v2",
                }  # 304 response (None content)
            
            # FRESH –∏–ª–∏ STALE –∫—ç—à –Ω–∞–π–¥–µ–Ω
            if cache_metadata and cached_data:
                computation_ms = int((time.time() - start_time) * 1000)
                
                # –°—Ç—Ä–æ–∏–º response —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
                response_data = {
                    "cached": True,
                    "cache_key": cache_metadata.cache_key,
                    "model_name": cache_metadata.model_name,
                    "last_updated": cache_metadata.last_updated.isoformat(),
                    "compute_ms": computation_ms,
                    "llm_ms": cache_metadata.llm_latency_ms,
                    "data": cached_data
                }
                
                headers = {
                    "ETag": cache_metadata.etag,
                    "X-Cache": "STALE" if cache_metadata.is_stale else "HIT",
                    "X-Cache-Age": str(cache_metadata.cache_age),
                    "X-Generated-At": cache_metadata.last_updated.isoformat(),
                    "X-LLM-Model": cache_metadata.model_name,
                    "X-Features-Version": "v2",
                    "X-Cache-Key": cache_metadata.cache_key[:16] + "...",
                    "X-LLM-Latency-MS": str(cache_metadata.llm_latency_ms),
                }
                
                # üîÑ –ü–ª–∞–Ω–∏—Ä—É–µ–º —Ñ–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–ª—è STALE –¥–∞–Ω–Ω—ã—Ö
                if needs_background_refresh:
                    logger.info(f"üöÄ Scheduling background refresh for stale cache {cache_metadata.cache_key[:16]}...")
                    self.cache_service.schedule_background_refresh(
                        str(user_id), request_data, self._generate_fresh_insights
                    )
                
                return response_data, headers
            
            # Cache MISS –∏–ª–∏ Bypass —Ä–µ–∂–∏–º - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
            logger.info(f"Cache MISS or BYPASS for user {user_id}")
        
        # üî• –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        
        # –ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        prompt_data = await self._prepare_prompt_data(user_id, db, request)
        
        # üî• –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ —Å LLM
        computation_start = time.time()
        llm_start = time.time()
        
        logger.info(f"üöÄ Computing fresh insights for user {user_id}")
        
        insights_data = await self._compute_insights(user_id, request, db)
        llm_ms = int((time.time() - llm_start) * 1000)
        compute_ms = int((time.time() - computation_start) * 1000)
        
        # üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –Ω–æ–≤—ã–π SWR –∫—ç—à
        cache_key, etag = self.cache_service.save_insights_with_swr(
            str(user_id), request_data, insights_data, compute_ms, llm_ms
        )
        
        # üìä –°—Ç—Ä–æ–∏–º response —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ SWR
        response_data = {
            "cached": False,
            "cache_key": cache_key,
            "model_name": request.model,
            "last_updated": datetime.now().isoformat(),
            "compute_ms": compute_ms,
            "llm_ms": llm_ms,
            "data": insights_data
        }
        
        headers = {
            "ETag": etag,
            "X-Cache": "MISS",
            "X-Cache-Age": "0",
            "X-Cache-Key": cache_key[:16] + "...",
            "X-LLM-Model": request.model,
            "X-LLM-Latency-MS": str(llm_ms),
            "X-Generated-At": datetime.now().isoformat(),
            "X-Features-Version": "v2"
        }
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
        total_elapsed = int((time.time() - start_time) * 1000)
        self.cache_service.log_cache_operation(
            operation="get_insights_swr",
            cache_key=cache_key[:16] + "...",
            cache_state="MISS",
            elapsed_ms=total_elapsed,
            llm_ms=llm_ms,
            user_id=str(user_id)
        )
        
        return response_data, headers
    
    async def _prepare_prompt_data(self, user_id: UUID, db: Session, request: UnifiedInsightsRequest) -> Dict[str, Any]:
                "model_name": cache_metadata.model_name,
                "last_updated": cache_metadata.last_updated.isoformat(),
                "compute_ms": 0,  # –∏–∑ –∫—ç—à–∞, –≤—Ä–µ–º–µ–Ω–∏ –Ω–µ —Ç—Ä–∞—Ç–∏–ª–∏
                "llm_ms": 0,
                "data": cached_data
            }
            
            headers = {
                "X-Cache": CacheState.HIT,
                "X-Cache-Key": cache_key,
                "X-LLM-Latency-MS": "0"
            }
            
        elif cache_state == CacheState.BYPASS or cache_param == CacheMode.BYPASS:
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∫—ç—à–∞
            logger.info(f"Cache BYPASS for user {user_id}")
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω—Å–∞–π—Ç—ã –±–µ–∑ –∫—ç—à–∞
            insights_data = await self._compute_insights(user_id, request, db)
            llm_ms = int((time.time() - llm_start) * 1000)
            compute_ms = int((time.time() - computation_start) * 1000)
            
            response_data = {
                "cached": False,
                "cache_key": cache_key,
                "model_name": request.model,
                "last_updated": datetime.utcnow().isoformat(),
                "compute_ms": compute_ms,
                "llm_ms": llm_ms,
                "data": insights_data
            }
            
            headers = {
                "X-Cache": CacheState.BYPASS,
                "X-Cache-Key": cache_key,
                "X-LLM-Latency-MS": str(llm_ms)
            }
            
        elif cache_state == CacheState.REFRESH or cache_param == CacheMode.REFRESH:
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞
            logger.info(f"Cache REFRESH for user {user_id}")
            
            # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã
            insights_data = await self._compute_insights(user_id, request, db)
            llm_ms = int((time.time() - llm_start) * 1000)
            compute_ms = int((time.time() - computation_start) * 1000)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            self.safe_cache_save(
                cache_key, insights_data, request.model, compute_ms, llm_ms, CacheMode.DEFAULT
            )
            
            response_data = {
                "cached": False,
                "cache_key": cache_key,
                "model_name": request.model,
                "last_updated": datetime.utcnow().isoformat(),
                "compute_ms": compute_ms,
                "llm_ms": llm_ms,
                "data": insights_data
            }
            
            headers = {
                "X-Cache": CacheState.REFRESH,
                "X-Cache-Key": cache_key,
                "X-LLM-Latency-MS": str(llm_ms)
            }
            
        else:
            # MISS - –≤—ã—á–∏—Å–ª–∏–º –∏ —Å–æ—Ö—Ä–∞–Ω–∏–º
            logger.info(f"Cache MISS for user {user_id}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º single-flight –ª–æ–∫
            locked, lock_key = self.cache_service.acquire_computation_lock(cache_key)
            
            if not locked:
                # –ö—Ç–æ-—Ç–æ —É–∂–µ –≤—ã—á–∏—Å–ª—è–µ—Ç, –∂–¥—ë–º –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
                # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∑–¥–µ—Å—å –±—ã–ª–∞ –±—ã –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                raise HTTPException(
                    status_code=status.HTTP_429_TOO_MANY_REQUESTS,
                    detail="Computation in progress, please retry shortly"
                )
            
            try:
                # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω—Å–∞–π—Ç—ã
                insights_data = await self._compute_insights(user_id, request, db)
                llm_ms = int((time.time() - llm_start) * 1000)
                compute_ms = int((time.time() - computation_start) * 1000)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                self.safe_cache_save(
                    cache_key, insights_data, request.model, compute_ms, llm_ms, CacheMode.DEFAULT
                )
                
                response_data = {
                    "cached": False,
                    "cache_key": cache_key,
                    "model_name": request.model,
                    "last_updated": datetime.utcnow().isoformat(),
                    "compute_ms": compute_ms,
                    "llm_ms": llm_ms,
                    "data": insights_data
                }
                
                headers = {
                    "X-Cache": CacheState.MISS,
                    "X-Cache-Key": cache_key,
                    "X-LLM-Latency-MS": str(llm_ms)
                }
                
            finally:
                # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ª–æ–∫
                self.cache_service.release_computation_lock(lock_key)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
        total_elapsed = int((time.time() - start_time) * 1000)
        self.cache_service.log_cache_operation(
            operation="get_insights",
            cache_key=cache_key,
            cache_state=cache_state,
            elapsed_ms=total_elapsed,
            llm_ms=response_data.get("llm_ms", 0),
            user_id=str(user_id),
            model_version=response_data["model_name"]
        )
        
        return response_data, headers
    
    async def _prepare_prompt_data(
        self,
        user_id: UUID,
        db: Session,
        request: UnifiedInsightsRequest
    ) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä—É—é—â–∞—è —á–∞—Å—Ç—å)"""
        # –ó–¥–µ—Å—å –∑–∞–≥–ª—É—à–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
        # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ —Ç–æ–º—É —á—Ç–æ –µ—Å—Ç—å –≤ InsightsPrepareService
        
        return {
            "positions": [
                {
                    "symbol": "AAPL",
                    "quantity": 100,
                    "price": 150.0
                },
                {
                    "symbol": "GOOGL", 
                    "quantity": 50,
                    "price": 2800.0
                }
            ],
            "metrics": {
                "total_value": 290000.0,
                "number_of_positions": 2,
                "top_concentration": 0.48
            }
        }
    
    async def _compute_insights(
        self,
        user_id: UUID,
        request: UnifiedInsightsRequest,
        db: Session
    ) -> Dict[str, Any]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ AI –∏–Ω—Å–∞–π—Ç–æ–≤ (—ç–º—É–ª–∏—Ä—É–µ–º)"""
        # –ó–¥–µ—Å—å –∑–∞–≥–ª—É—à–∫–∞ - –≤—ã–∑–æ–≤ —Ä–µ–∞–ª—å–Ω–æ–≥–æ LLM
        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã –≤—ã–∑–æ–≤ InsightsEnrichLLMService
        
        return {
            "portfolio_summary": {
                "risk_score": "Medium",
                "diversification": "Fair",
                "recommendation": "Consider adding international exposure"
            },
            "positions_analysis": [
                {
                    "symbol": "AAPL",
                    "insights": {
                        "valuation": "Fairly valued",
                        "momentum": "Strong",
                        "action": "Hold"
                    }
                },
                {
                    "symbol": "GOOGL",
                    "insights": {
                        "valuation": "Undervalued", 
                        "momentum": "Neutral",
                        "action": "Buy on dips"
                    }
                }
            ],
            "market_outlook": {
                "current_trend": "Bullish",
                "key_risks": ["Interest rates", "Tech regulation"],
                "opportunities": ["International stocks", "REITs"]
            }
        }
    
    def safe_cache_save(
        self,
        cache_key: str,
        data: Dict[str, Any],
        model_name: str,
        compute_ms: int,
        llm_ms: int,
        mode: str
    ) -> None:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            self.cache_service.set_cache_entry(
                cache_key, data, model_name, compute_ms, llm_ms, mode
            )
        except Exception as e:
            logger.error(f"Failed to save to cache: {e}")
            # –ù–µ –ø–∞–¥–∞–µ–º –Ω–∞ –æ—à–∏–±–∫–µ –∫—ç—à–∞ - —ç—Ç–æ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è


# === API Endpoints ===

unified_service = UnifiedInsightsService()


@router.get("/", response_model=UnifiedInsightsResponse)
async def get_unified_insights(
    user_id: UUID = Query(..., description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"),
    cache: str = Query(CacheMode.DEFAULT, description="Cache mode: default|bypass|refresh"),
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± —á–µ—Ä–µ–∑ –∑–∞–≥–æ–ª–æ–≤–æ–∫
    x_cache_mode: Optional[str] = Header(None, alias="X-Cache-Mode"),
    # ETag –ø–æ–¥–¥–µ—Ä–∂–∫–∞
    if_none_match: Optional[str] = Header(None, alias="If-None-Match"),
    db: Session = Depends(get_db)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ AI –∏–Ω—Å–∞–π–ª–æ–≤ —Å —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    
    –†–µ–∞–ª–∏–∑—É–µ—Ç –∫–æ–Ω—Ç—Ä–∞–∫—Ç —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏:
    - –†–µ–∂–∏–º—ã default/bypass/refresh —á–µ—Ä–µ–∑ query –∏–ª–∏ header
    - –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ response fields –∏ headers  
    - –ú–µ—Ç—Ä–∏–∫–∏ –∑–∞–¥–µ—Ä–∂–∫–∏ LLM –∏ E2E
    - –ó–∞—â–∏—Ç–∞ –æ—Ç —à—Ç–æ—Ä–º–æ–≤ —á–µ—Ä–µ–∑ single-flight
    
    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        cache: –†–µ–∂–∏–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—É –µ—Å–ª–∏ –µ—Å—Ç—å)
        x_cache_mode: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–µ—Ä–µ–¥–∞—á–∏ —Ä–µ–∂–∏–º–∞ —á–µ—Ä–µ–∑ header
        db: –°–µ—Å—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    
    Returns:
        Insights —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∫—ç—à–∞ —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
    """
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—É)
    cache_mode = cache if cache in [CacheMode.DEFAULT, CacheMode.BYPASS, CacheMode.REFRESH] else \
                 x_cache_mode if x_cache_mode in [CacheMode.DEFAULT, CacheMode.BYPASS, CacheMode.REFRESH] else \
                 CacheMode.DEFAULT
    
    # –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ query –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    request = UnifiedInsightsRequest(
        horizon_months=6,  # –î–µ—Ñ–æ–ª—Ç, –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑ query
        risk_profile="Balanced",
        model="llama3.1:8b",
        temperature=0.2,
        top_p=1.0,
        max_tokens=400,
        locale="en",
        include_signals=True
    )
    
    try:
        response_data, headers_data = await unified_service.get_insights(
            user_id, request, cache_mode, db, if_none_match
        )
        
        # –°–æ–∑–¥–∞—ë–º Response —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
        response = JSONResponse(
            content=response_data,
            headers=headers_data
        )
        return response
        
    except Exception as e:
        logger.error(f"Unified insights error for user {user_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Insights computation failed: {str(e)}"
        )


@router.post("/", response_model=UnifiedInsightsResponse)  
async def post_unified_insights(
    request: UnifiedInsightsRequest,
    user_id: UUID = Query(..., description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"),
    cache: str = Query(CacheMode.DEFAULT, description="Cache mode: default|bypass|refresh"),
    db: Session = Depends(get_db)
) -> UnifiedInsightsResponse:
    """
    POST –≤–µ—Ä—Å–∏—è –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ —Å–ª–æ–∂–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ body
    
    –ê–Ω–∞–ª–æ–≥–∏—á–Ω–∞ GET, –Ω–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –ø–æ–ª–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ JSON body
    –≤–º–µ—Å—Ç–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö query –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
    """
    
    cache_mode = cache if cache in [CacheMode.DEFAULT, CacheMode.BYPASS, CacheMode.REFRESH] else CacheMode.DEFAULT
    
    try:
        response_data, headers_data = await unified_service.get_insights(
            user_id, request, cache_mode, db
        )
        
        return JSONResponse(
            content=response_data,
            headers=headers_data
        )
        
    except Exception as e:
        logger.error(f"POST unified insights error for user {user_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Insights computation failed: {str(e)}"
        )


@router.delete("/cache/invalidate")
async def invalidate_unified_cache(
    request: CacheInvalidateRequest
) -> Dict[str, Any]:
    """
    –ò–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—è –∫—ç—à–∞ —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
    
    Args:
        request: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–∏
    
    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–∏
    """
    
    cache_service = UnifiedCacheService()
    
    if request.full_clear:
        # –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –∫—ç—à–µ–π
        pattern = "insights:unified:*"
        keys = cache_service.redis_client.keys(pattern)
        
        if keys:
            deleted_count = cache_service.redis_client.delete(*keys)
            return {
                "invalidated_keys": deleted_count,
                "type": "full_invalidate",
                "timestamp": datetime.utcnow().isoformat()
            }
        else:
            return {
                "invalidated_keys": 0,
                "type": "no_entries_found",
                "timestamp": datetime.utcnow().isoformat()
            }
    
    elif request.user_id:
        # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        result = cache_service.invalidate_user_cache(request.user_id)
        return {
            **result,
            "timestamp": datetime.utcnow().isoformat()
        }
    
    else:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Either user_id or full_clear=true required"
        )


@router.get("/cache/stats")
async def get_cache_stats() -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫—ç—à–∞ —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
    
    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫—ç—à–∞
    """
    
    cache_service = UnifiedCacheService()
    return cache_service.get_cache_stats()


# === Optional: ETag support ===

@router.get("/etag", response_model=UnifiedInsightsResponse)
async def get_insights_with_etag(
    user_id: UUID = Query(..., description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"),
    cache: str = Query(CacheMode.DEFAULT),
    if_none_match: Optional[str] = Header(None),
    db: Session = Depends(get_db)
) -> JSONResponse:
    """
    –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ ETag –¥–ª—è HTTP –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
    
    –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –ø–µ—Ä–µ–¥–∞—ë—Ç If-None-Match –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∞–∫—Ç—É–∞–ª—å–Ω—ã–º ETag,
    –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 304 Not Modified –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö.
    """
    
    request = UnifiedInsightsRequest()  # –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    cache_mode = cache if cache in [CacheMode.DEFAULT, CacheMode.BYPASS, CacheMode.REFRESH] else CacheMode.DEFAULT
    
    try:
        response_data, headers_data = await unified_service.get_insights(
            user_id, request, cache_mode, db
        )
        
        # –°–æ–∑–¥–∞—ë–º ETag –Ω–∞ –æ—Å–Ω–æ–≤–µ cache_key –∏ last_updated
        etag = f'"{response_data["cache_key"]}:{response_data["last_updated"]}"'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º If-None-Match
        if if_none_match and if_none_match == etag:
            return JSONResponse(
                content=None,
                status_code=304,
                headers={
                    "ETag": etag,
                    **headers_data
                }
            )
        
        response = JSONResponse(
            content=response_data,
            headers={
                "ETag": etag,
                **headers_data
            }
        )
        
        return response
        
    except Exception as e:
        logger.error(f"ETag insights error for user {user_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Insights computation failed: {str(e)}"
        )
