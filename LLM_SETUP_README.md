# üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç: –õ–æ–∫–∞–ª—å–Ω—ã–µ LLM –¥–ª—è AI Portfolio Analyzer

## –ß—Ç–æ –º—ã —Å–æ–∑–¥–∞–ª–∏

–ü–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö LLM (Llama, Gemma, Qwen) —á–µ—Ä–µ–∑ Ollama –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ AI Portfolio Analyzer.

### üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤

```
infra/ollama/
‚îú‚îÄ‚îÄ README.md          # –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ Ollama
‚îú‚îÄ‚îÄ install.ps1        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama
‚îî‚îÄ‚îÄ pull_models.ps1    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π LLM

backend/app/routers/
‚îî‚îÄ‚îÄ llm_proxy.py       # FastAPI —Ä–æ—É—Ç–µ—Ä –¥–ª—è Ollama API

backend/app/web/ui/
‚îî‚îÄ‚îÄ llm_test.html      # –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è LLM

backend/app/main.py    # –û–±–Ω–æ–≤–ª–µ–Ω —Å –Ω–æ–≤—ã–º —Ä–æ—É—Ç–µ—Ä–æ–º
backend/requirements.txt # –î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å tenacity
```

## üéØ –ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫

### 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama
```powershell
cd infra/ollama
.\install.ps1
```

### 2. –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª–∏ LLM
```powershell
.\pull_models.ps1
```

### 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama —Å–µ—Ä–≤–µ—Ä
```bash
ollama serve
```

### 4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ FastAPI
```bash
cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 5. –û—Ç–∫—Ä–æ–π—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
```
http://localhost:8000/ui/llm_test.html
```

## üîß API Endpoints

### POST `/llm/chat`
–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM:
```json
{
  "model": "llama3.1:8b",
  "system": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π",
  "prompt": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –º–æ–π –ø–æ—Ä—Ç—Ñ–µ–ª—å: 60% –∞–∫—Ü–∏–∏, 30% –æ–±–ª–∏–≥–∞—Ü–∏–∏",
  "temperature": 0.7,
  "max_tokens": 1000
}
```

### GET `/llm/models`
–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

### GET `/llm/health`
–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è Ollama

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

1. **–û—Ç–∫—Ä–æ–π—Ç–µ** `http://localhost:8000/ui/llm_test.html`
2. **–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å** (llama3.1:8b, gemma2:9b, qwen2.5-coder:7b)
3. **–í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º–ø—Ç** –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è
4. **–ù–∞–∂–º–∏—Ç–µ "–û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å"**
5. **–ü–æ–ª—É—á–∏—Ç–µ JSON –æ—Ç–≤–µ—Ç** –æ—Ç LLM

## üí° –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–º–ø—Ç–æ–≤

### –ê–Ω–∞–ª–∏–∑ –ø–æ—Ä—Ç—Ñ–µ–ª—è
```
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –º–æ–π –ø–æ—Ä—Ç—Ñ–µ–ª—å: 60% –∞–∫—Ü–∏–∏ (AAPL, MSFT, GOOGL), 30% –æ–±–ª–∏–≥–∞—Ü–∏–∏ (BND), 10% –∑–æ–ª–æ—Ç–æ (GLD). 
–ö–∞–∫–∏–µ —Ä–∏—Å–∫–∏ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏? –î–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
```

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL
```
–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π. 
–¢–∞–±–ª–∏—Ü–∞: portfolio_valuations_eod —Å –ø–æ–ª—è–º–∏ date, portfolio_id, total_value.
```

### –ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤
```
–û—Ü–µ–Ω–∏ —Ä–∏—Å–∫–∏ –º–æ–µ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è: 70% –∞–∫—Ü–∏–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–ø–∞–Ω–∏–π, 20% –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã, 10% –Ω–∞–ª–∏—á–Ω—ã–µ.
–ö–∞–∫–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –º–æ–≥—É—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–æ—Ç–µ—Ä–µ 20%+ —Å—Ç–æ–∏–º–æ—Å—Ç–∏?
```

## üêõ Troubleshooting

### Ollama –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ—Ä—Ç 11434
netstat -an | findstr 11434

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ Ollama
ollama serve
```

### –ú–æ–¥–µ–ª—å –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
ollama list

# –ü–µ—Ä–µ—Å–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å
ollama pull llama3.1:8b
```

### –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (q4_0)
- –ó–∞–∫—Ä–æ–π—Ç–µ –¥—Ä—É–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
- –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ vLLM –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | –°–∫–æ—Ä–æ—Å—Ç—å | –ö–∞—á–µ—Å—Ç–≤–æ | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|--------|--------|----------|----------|------------|
| llama3.1:8b | 4.1GB | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ |
| gemma2:9b | 5.4GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã |
| qwen2.5-coder:7b | 4.4GB | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | –ö–æ–¥-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è |

## üîÑ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø–æ—Ä—Ç—Ñ–µ–ª–µ–º**: –ü–æ–¥–∫–ª—é—á–∏—Ç—å LLM –∫ —Ä–µ–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º –ø–æ—Ä—Ç—Ñ–µ–ª—è
2. **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ**: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –æ—Ç–≤–µ—Ç—ã LLM –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
3. **–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å embeddings –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
4. **vLLM**: –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ vLLM –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞ —Å –≤—ã—Å–æ–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Ollama Documentation](https://ollama.ai/docs)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [Tenacity Retry Library](https://tenacity.readthedocs.io/)

